{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def extract_contour_for_dim_image(image : np.ndarray):\n",
    "    # to grayscale image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # get edges\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), -10)\n",
    "    adaptive_binary = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7,3)\n",
    "    edges = cv2.Canny(adaptive_binary,100,200)\n",
    "    binarized_grad = 255 - edges\n",
    "\n",
    "    # denoises again\n",
    "    open_binarized_grad = cv2.morphologyEx(\n",
    "        binarized_grad, \n",
    "        cv2.MORPH_OPEN, \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7)))\n",
    "\n",
    "    # get contours\n",
    "    contours, _ = cv2.findContours(open_binarized_grad, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # image size\n",
    "    height, width = binarized_grad.shape\n",
    "    image_area = height * width\n",
    "\n",
    "    # sort contour index\n",
    "    index_sort = sorted(range(len(contours)), key=lambda i : cv2.contourArea(contours[i]),reverse=True)\n",
    "    contours_sort = [contours[i] for i in index_sort]\n",
    "\n",
    "    # get area and perimeter\n",
    "    contour_area = [cv2.contourArea(contours_sort[i]) for i in range(len(index_sort))]\n",
    "    contour_peri = [cv2.arcLength(contours_sort[i], True) for i in range(len(index_sort))]\n",
    "    approx = [cv2.approxPolyDP(contours_sort[i], 0.001 * contour_peri[i], True) for i in range(len(index_sort))]\n",
    "    bounding_box = [cv2.boundingRect(approx[i]) for i in range(len(index_sort))]\n",
    "    is_card = list(filter(lambda x : x >= 0, [i if contour_area[i] >= 0.48 * image_area and contour_area[i] <= 0.7 * image_area else -1 for i in range(len(index_sort))]))\n",
    "\n",
    "    return len(is_card) > 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def extract_contour_for_pop_image(image : np.ndarray):\n",
    "    # to grayscale image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # get edges\n",
    "    _, otsu_grad = cv2.threshold(gray,0,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # get contours\n",
    "    contours, _ = cv2.findContours(otsu_grad, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # image size\n",
    "    height, width = otsu_grad.shape\n",
    "    image_area = height * width\n",
    "\n",
    "    # sort contour index\n",
    "    index_sort = sorted(range(len(contours)), key=lambda i : cv2.contourArea(contours[i]),reverse=True)\n",
    "    contours_sort = [contours[i] for i in index_sort]\n",
    "\n",
    "    # get area and perimeter\n",
    "    contour_peri = [cv2.arcLength(contours_sort[i], True) for i in range(len(index_sort))]\n",
    "    approx = [cv2.approxPolyDP(contours_sort[i], 0.001 * contour_peri[i], True) for i in range(len(index_sort))]\n",
    "    bounding_box = [cv2.boundingRect(approx[i]) for i in range(len(index_sort))]\n",
    "    contour_area = [bounding_box[i][2] * bounding_box[i][3]  for i in range(len(index_sort))]\n",
    "    is_card = list(filter(lambda x : x >= 0, [i if contour_area[i] >= 0.48 * image_area and contour_area[i] <= 0.6 * image_area else -1 for i in range(len(index_sort))]))\n",
    "\n",
    "    return len(is_card) > 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "total_number_of_images = 0\n",
    "contour_found = 0\n",
    "for file_path in glob.glob(os.path.join('data','*')):\n",
    "    image_file_path = os.path.join(file_path, \"back.jpg\")\n",
    "    try:\n",
    "        image = cv2.imread(image_file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if extract_contour_for_pop_image(image):\n",
    "            contour_found += 1\n",
    "        elif extract_contour_for_dim_image(image):\n",
    "            contour_found += 1\n",
    "        total_number_of_images += 1\n",
    "    except:\n",
    "        pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(f\"Current images whose content found: {contour_found}\")\n",
    "print(f\"Current processed images: {total_number_of_images}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current images whose content found: 7401\n",
      "Current processed images: 8214\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('psa': conda)"
  },
  "interpreter": {
   "hash": "b4d4caaa904f1b779aa3a7c96dea51e4fb743695ed9daaf7cfb1df6a759db69f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}